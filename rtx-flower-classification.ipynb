{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-11T17:27:37.129369Z","iopub.status.busy":"2023-07-11T17:27:37.128828Z","iopub.status.idle":"2023-07-11T17:27:46.597304Z","shell.execute_reply":"2023-07-11T17:27:46.596168Z","shell.execute_reply.started":"2023-07-11T17:27:37.129340Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","import keras\n","import os"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-11T17:54:46.286526Z","iopub.status.busy":"2023-07-11T17:54:46.286160Z","iopub.status.idle":"2023-07-11T19:56:34.193186Z","shell.execute_reply":"2023-07-11T19:56:34.190631Z","shell.execute_reply.started":"2023-07-11T17:54:46.286501Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 4999 files belonging to 5 classes.\n","Using 4500 files for training.\n","Using 499 files for validation.\n","Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential_4 (Sequential)   (None, 128, 128, 3)       0         \n","                                                                 \n"," rescaling_2 (Rescaling)     (None, 128, 128, 3)       0         \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 126, 126, 128)     3584      \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 63, 63, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_6 (Dropout)         (None, 63, 63, 128)       0         \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 61, 61, 128)       147584    \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  (None, 30, 30, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 28, 28, 8)         9224      \n","                                                                 \n"," dropout_7 (Dropout)         (None, 28, 28, 8)         0         \n","                                                                 \n"," global_max_pooling2d (Globa  (None, 8)                0         \n"," lMaxPooling2D)                                                  \n","                                                                 \n"," flatten_2 (Flatten)         (None, 8)                 0         \n","                                                                 \n"," dense_4 (Dense)             (None, 512)               4608      \n","                                                                 \n"," dropout_8 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 5)                 2565      \n","                                                                 \n","=================================================================\n","Total params: 167,565\n","Trainable params: 167,565\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","141/141 [==============================] - 211s 1s/step - loss: 1.5966 - accuracy: 0.2349 - val_loss: 1.5841 - val_accuracy: 0.2766\n","Epoch 2/30\n","141/141 [==============================] - 208s 1s/step - loss: 1.3512 - accuracy: 0.3936 - val_loss: 1.1415 - val_accuracy: 0.5611\n","Epoch 3/30\n","141/141 [==============================] - 203s 1s/step - loss: 1.1318 - accuracy: 0.5336 - val_loss: 1.0443 - val_accuracy: 0.5872\n","Epoch 4/30\n","141/141 [==============================] - 203s 1s/step - loss: 1.0628 - accuracy: 0.5782 - val_loss: 0.9935 - val_accuracy: 0.6132\n","Epoch 5/30\n","141/141 [==============================] - 204s 1s/step - loss: 1.0180 - accuracy: 0.6009 - val_loss: 0.9862 - val_accuracy: 0.6052\n","Epoch 6/30\n","141/141 [==============================] - 211s 1s/step - loss: 0.9812 - accuracy: 0.6140 - val_loss: 0.9864 - val_accuracy: 0.6132\n","Epoch 7/30\n","141/141 [==============================] - 215s 2s/step - loss: 0.9544 - accuracy: 0.6309 - val_loss: 0.9266 - val_accuracy: 0.6253\n","Epoch 8/30\n","141/141 [==============================] - 206s 1s/step - loss: 0.9284 - accuracy: 0.6356 - val_loss: 0.9204 - val_accuracy: 0.6293\n","Epoch 9/30\n","141/141 [==============================] - 207s 1s/step - loss: 0.9139 - accuracy: 0.6420 - val_loss: 0.9930 - val_accuracy: 0.5972\n","Epoch 10/30\n","141/141 [==============================] - 203s 1s/step - loss: 0.9009 - accuracy: 0.6484 - val_loss: 0.8860 - val_accuracy: 0.6413\n","Epoch 11/30\n","141/141 [==============================] - 203s 1s/step - loss: 0.8739 - accuracy: 0.6544 - val_loss: 0.8484 - val_accuracy: 0.6613\n","Epoch 12/30\n","141/141 [==============================] - 202s 1s/step - loss: 0.8445 - accuracy: 0.6738 - val_loss: 0.8759 - val_accuracy: 0.6653\n","Epoch 13/30\n","141/141 [==============================] - 209s 1s/step - loss: 0.8506 - accuracy: 0.6729 - val_loss: 0.8592 - val_accuracy: 0.6653\n","Epoch 14/30\n","141/141 [==============================] - 205s 1s/step - loss: 0.8317 - accuracy: 0.6838 - val_loss: 0.8360 - val_accuracy: 0.6874\n","Epoch 15/30\n","141/141 [==============================] - 205s 1s/step - loss: 0.8305 - accuracy: 0.6824 - val_loss: 0.8040 - val_accuracy: 0.6754\n","Epoch 16/30\n","141/141 [==============================] - 203s 1s/step - loss: 0.8060 - accuracy: 0.6833 - val_loss: 0.7995 - val_accuracy: 0.6954\n","Epoch 17/30\n","141/141 [==============================] - 204s 1s/step - loss: 0.8086 - accuracy: 0.6827 - val_loss: 0.7937 - val_accuracy: 0.6713\n","Epoch 18/30\n","141/141 [==============================] - 204s 1s/step - loss: 0.7939 - accuracy: 0.6964 - val_loss: 0.7830 - val_accuracy: 0.6914\n","Epoch 19/30\n","141/141 [==============================] - 203s 1s/step - loss: 0.7752 - accuracy: 0.6987 - val_loss: 0.7780 - val_accuracy: 0.6934\n","Epoch 20/30\n","141/141 [==============================] - 207s 1s/step - loss: 0.7649 - accuracy: 0.7067 - val_loss: 0.7614 - val_accuracy: 0.6874\n","Epoch 21/30\n","141/141 [==============================] - 210s 1s/step - loss: 0.7832 - accuracy: 0.7027 - val_loss: 0.7479 - val_accuracy: 0.7174\n","Epoch 22/30\n","141/141 [==============================] - 219s 2s/step - loss: 0.7750 - accuracy: 0.7033 - val_loss: 0.7367 - val_accuracy: 0.7214\n","Epoch 23/30\n","141/141 [==============================] - 207s 1s/step - loss: 0.7438 - accuracy: 0.7173 - val_loss: 0.7594 - val_accuracy: 0.6914\n","Epoch 24/30\n","141/141 [==============================] - 207s 1s/step - loss: 0.7527 - accuracy: 0.7118 - val_loss: 0.7951 - val_accuracy: 0.6994\n","Epoch 25/30\n","141/141 [==============================] - 206s 1s/step - loss: 0.7338 - accuracy: 0.7113 - val_loss: 0.7314 - val_accuracy: 0.7154\n","Epoch 26/30\n","141/141 [==============================] - 205s 1s/step - loss: 0.7382 - accuracy: 0.7187 - val_loss: 0.7424 - val_accuracy: 0.6954\n","Epoch 27/30\n","141/141 [==============================] - 208s 1s/step - loss: 0.7326 - accuracy: 0.7144 - val_loss: 0.7317 - val_accuracy: 0.7154\n","Epoch 28/30\n","141/141 [==============================] - 207s 1s/step - loss: 0.7099 - accuracy: 0.7289 - val_loss: 0.7664 - val_accuracy: 0.7094\n","Epoch 29/30\n","141/141 [==============================] - 206s 1s/step - loss: 0.6988 - accuracy: 0.7269 - val_loss: 0.6958 - val_accuracy: 0.7315\n","Epoch 30/30\n","141/141 [==============================] - 207s 1s/step - loss: 0.7224 - accuracy: 0.7224 - val_loss: 0.7172 - val_accuracy: 0.7174\n"]}],"source":["from tensorflow.keras import layers\n","batch_size = 32\n","epochs = 30\n","input_shape = (128, 128, 3)\n","classes = 10\n","training_data,val_data  = keras.utils.image_dataset_from_directory(\"/kaggle/input/5-flower-types-classification-dataset/flower_images\",\n","                                                         image_size=(128, 128), label_mode='categorical',\n","                                                         batch_size=batch_size, validation_split=0.1, subset=\"both\", seed=23)\n","# val_data = keras.utils.image_dataset_from_directory(\"/kaggle/input/flower-classification-5-classes-roselilyetc/Flower Classification V2/V2/Validation Data\",\n","#                                                          image_size=(128, 128), label_mode='categorical')\n","simple_aug = tf.keras.Sequential(\n","    [\n","        layers.RandomFlip(\"horizontal\"),\n","        layers.RandomRotation(0.1),\n","        layers.RandomZoom(0.1),\n","    ]\n",")\n","\n","model = keras.Sequential(\n","    [\n","        keras.Input(shape=input_shape),\n","        simple_aug,\n","        layers.Rescaling(scale=1./255),\n","        \n","        layers.Conv2D(64, (4,4), activation=\"relu\"),\n","        layers.MaxPooling2D(pool_size=(2,2), strides=2),\n","        layers.Dropout(0.15),\n","        \n","        layers.Conv2D(32, (3,3), activation=\"relu\"),\n","        layers.MaxPooling2D(pool_size=(2,2), strides=2),\n","        \n","        layers.Conv2D(16, (3,3), activation=\"relu\"),\n","        layers.Dropout(0.15),\n","        \n","        layers.Flatten(),\n","        layers.Dense(512, activation=\"relu\"),\n","        layers.Dropout(0.5),\n","        layers.Dense(classes, activation=\"softmax\"),\n","    ]\n",")\n","model.summary()\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","model.fit(training_data, batch_size=batch_size, epochs=epochs, validation_data=val_data)\n","model.save('rtxinternship_flowers.h5')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-07-11T20:07:06.022824Z","iopub.status.busy":"2023-07-11T20:07:06.022413Z","iopub.status.idle":"2023-07-11T20:07:06.125964Z","shell.execute_reply":"2023-07-11T20:07:06.124408Z","shell.execute_reply.started":"2023-07-11T20:07:06.022775Z"},"trusted":true},"outputs":[],"source":["model2 = keras.Sequential(\n","    [\n","        keras.Input(shape=input_shape),\n","        layers.Rescaling(scale=1./255),\n","        \n","        layers.Conv2D(64, (4,4), activation=\"relu\"),\n","        layers.MaxPooling2D(pool_size=(2,2), strides=2),\n","        layers.Dropout(0.15),\n","        \n","        layers.Conv2D(32, (3,3), activation=\"relu\"),\n","        layers.MaxPooling2D(pool_size=(2,2), strides=2),\n","        \n","        layers.Conv2D(16, (3,3), activation=\"relu\"),\n","        layers.Dropout(0.15),\n","        \n","        layers.Flatten(),\n","        layers.Dense(512, activation=\"relu\"),\n","        layers.Dense(classes, activation=\"softmax\"),\n","    ]\n",")\n","\n","\n","model2.load_weights(\"rtxinternship_flowers.h5\", skip_mismatch=True, by_name=True, options=None)\n","model2.save('rtxinternship_flowers_2.h5')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-11T20:07:26.161685Z","iopub.status.busy":"2023-07-11T20:07:26.160959Z","iopub.status.idle":"2023-07-11T20:07:31.989012Z","shell.execute_reply":"2023-07-11T20:07:31.987644Z","shell.execute_reply.started":"2023-07-11T20:07:26.161633Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]}],"source":["!mkdir model\n","!tensorflowjs_converter --input_format keras rtxinternship_flowers_2.h5 model/"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
